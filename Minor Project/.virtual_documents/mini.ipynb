import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split


df = pd.read_csv("loan.csv")


df


df.info()


# Count null values in id column
print(df['Applicant_ID'].isnull().sum())


df.count()


catergorical_cols = df.select_dtypes(include=["object"]).columns
numerical_cols = df.select_dtypes(include=["number"]).columns



catergorical_cols


numerical_cols


from sklearn.impute import SimpleImputer



num_imp = SimpleImputer(strategy = "mean")
df[numerical_cols] = num_imp.fit_transform(df[numerical_cols])


df.head()


cat_imp = SimpleImputer(strategy="most_frequent")
df[catergorical_cols] = cat_imp.fit_transform(df[catergorical_cols])


df.head()


df.info()


count = df["Loan_Approved"].value_counts()



from sklearn.preprocessing import LabelEncoder , OneHotEncoder

le = LabelEncoder()
df["Education_Level"] = le.fit_transform(df["Education_Level"])
df["Loan_Approved"] = le.fit_transform(df["Loan_Approved"])


cols = ["Employment_Status","Marital_Status","Loan_Purpose","Property_Area","Gender","Employer_Category"]


ohe = OneHotEncoder(drop="first",sparse_output=False , handle_unknown="ignore")
encoded = ohe.fit_transform(df[cols])
encoded_df = pd.DataFrame(encoded , columns=ohe.get_feature_names_out(cols), index=df.index)
df = pd.concat([df.drop(columns=cols),encoded_df],axis=1)


df.head()
df.info()


x = df.drop("Loan_Approved" , axis=1)
y = df["Loan_Approved"]





from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, confusion_matrix, accuracy_score, recall_score,f1_score

x_train , x_test , y_train,y_test = train_test_split(x,y,test_size = 0.2 , random_state = 42)

scaler = StandardScaler();
x_train = scaler.fit_transform(x_train);
x_test = scaler.transform(x_test)

lr = LogisticRegression()
lr.fit(x_train,y_train)
pred = lr.predict(x_test)


print("Precision_Score",precision_score(y_test,pred))
print("confusion_matrix",confusion_matrix(y_test,pred))
print("accuracy_score",accuracy_score(y_test,pred))
print("recall_score",recall_score(y_test,pred))
print("f1_score",f1_score(y_test,pred))


from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 5)

knn.fit(x_train,y_train)
pred = knn.predict(x_test)
print("Precision_Score",precision_score(y_test,pred))
print("confusion_matrix",confusion_matrix(y_test,pred))
print("accuracy_score",accuracy_score(y_test,pred))
print("recall_score",recall_score(y_test,pred))
print("f1_score",f1_score(y_test,pred))


from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()

nb.fit(x_train,y_train)
pred = nb.predict(x_test)
print("Precision_Score",precision_score(y_test,pred))
print("confusion_matrix",confusion_matrix(y_test,pred))
print("accuracy_score",accuracy_score(y_test,pred))
print("recall_score",recall_score(y_test,pred))
print("f1_score",f1_score(y_test,pred))


df["DTI_Ratio_sq"] = df["DTI_Ratio"]**2
df["Credit_score_sq"] = df["Credit_Score"]**2
df["Applicant_Income_log"] = np.log1p(df["Applicant_Income"])
x = df.drop(columns=["DTI_Ratio","Credit_Score","Loan_Approved","Applicant_Income"])
y = df["Loan_Approved"]



x_train , x_test , y_train,y_test = train_test_split(x,y,test_size = 0.2 , random_state = 42)

scaler = StandardScaler();
x_train = scaler.fit_transform(x_train);
x_test = scaler.transform(x_test)


lr = LogisticRegression()
lr.fit(x_train,y_train)
pred = lr.predict(x_test)




